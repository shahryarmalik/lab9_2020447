{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moAo1Tnq1qM3",
        "outputId": "8c6fe510-2ff4-4a53-dfe0-dfa1bbf3ff8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-_h52okim\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-_h52okim\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4293 sha256=38bc43772ba1abb8476f5fbbc8341f7011c43225dc00d21e7998e7af2cf19884\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ly23ew1j/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7H7OBNM1-yt",
        "outputId": "07527c82-486f-4331-df57-107c7a8f876f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "const int TILE_SIZE = 2;\n",
        "\n",
        "__global__ void matrixMultiplication(const int *matrixA, const int *matrixB, int *matrixResult, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    __shared__ int sharedA[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ int sharedB[TILE_SIZE][TILE_SIZE];\n",
        "\n",
        "    int result = 0;\n",
        "\n",
        "    for (int i = 0; i < (N + TILE_SIZE - 1) / TILE_SIZE; ++i) {\n",
        "        if ((row < N) && (i * TILE_SIZE + threadIdx.x < N)) {\n",
        "            sharedA[threadIdx.y][threadIdx.x] = matrixA[row * N + i * TILE_SIZE + threadIdx.x];\n",
        "        } else {\n",
        "            sharedA[threadIdx.y][threadIdx.x] = 0;\n",
        "        }\n",
        "\n",
        "        if ((col < N) && (i * TILE_SIZE + threadIdx.y < N)) {\n",
        "            sharedB[threadIdx.y][threadIdx.x] = matrixB[(i * TILE_SIZE + threadIdx.y) * N + col];\n",
        "        } else {\n",
        "            sharedB[threadIdx.y][threadIdx.x] = 0;\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        for (int j = 0; j < TILE_SIZE; ++j) {\n",
        "            result += sharedA[threadIdx.y][j] * sharedB[j][threadIdx.x];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        matrixResult[row * N + col] = result;\n",
        "    }\n",
        "}\n",
        "\n",
        "void printMatrix(const int *matrix, int rows, int cols) {\n",
        "    for (int i = 0; i < rows; ++i) {\n",
        "        for (int j = 0; j < cols; ++j) {\n",
        "            std::cout << matrix[i * cols + j] << \" \";  // Print without setw\n",
        "        }\n",
        "        std::cout << std::endl;\n",
        "    }\n",
        "    std::cout << std::endl;\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    const int N = 3;\n",
        "\n",
        "    const int matrixA[N][N] = {{1, 2, 3}, {4, 5, 6}, {7, 8, 9}};\n",
        "    const int matrixB[N][N] = {{9, 8, 7}, {6, 5, 4}, {3, 2, 1}};\n",
        "\n",
        "    int matrixC_cpu[N][N]; // Result matrix from CPU\n",
        "    int matrixC_gpu[N][N]; // Result matrix from GPU\n",
        "\n",
        "    int *d_matrixA, *d_matrixB, *d_matrixC;\n",
        "    cudaMalloc((void **)&d_matrixA, N * N * sizeof(int));\n",
        "    cudaMalloc((void **)&d_matrixB, N * N * sizeof(int));\n",
        "    cudaMalloc((void **)&d_matrixC, N * N * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_matrixA, &matrixA[0][0], N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_matrixB, &matrixB[0][0], N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 blockDim(2, 2);\n",
        "    dim3 gridDim((N + blockDim.x - 1) / blockDim.x, (N + blockDim.y - 1) / blockDim.y);\n",
        "\n",
        "    matrixMultiplication<<<gridDim, blockDim>>>(d_matrixA, d_matrixB, d_matrixC, N);\n",
        "\n",
        "    cudaMemcpy(&matrixC_gpu[0][0], d_matrixC, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            matrixC_cpu[i][j] = 0;\n",
        "            for (int k = 0; k < N; ++k) {\n",
        "                matrixC_cpu[i][j] += matrixA[i][k] * matrixB[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    std::cout << \"Matrix A:\" << std::endl;\n",
        "    printMatrix(&matrixA[0][0], N, N);\n",
        "    std::cout << \"Matrix B:\" << std::endl;\n",
        "    printMatrix(&matrixB[0][0], N, N);\n",
        "    std::cout << \"Result from CPU (matrixC_cpu):\" << std::endl;\n",
        "    printMatrix(&matrixC_cpu[0][0], N, N);\n",
        "\n",
        "    std::cout << \"Result from GPU (matrixC_gpu):\" << std::endl;\n",
        "    printMatrix(&matrixC_gpu[0][0], N, N);\n",
        "\n",
        "    bool resultMatch = true;\n",
        "    for (int i = 0; i < N; ++i) {\n",
        "        for (int j = 0; j < N; ++j) {\n",
        "            if (matrixC_cpu[i][j] != matrixC_gpu[i][j]) {\n",
        "                resultMatch = false;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (resultMatch) {\n",
        "        std::cout << \"Results match between CPU and GPU implementations.\" << std::endl;\n",
        "    } else {\n",
        "        std::cout << \"Results do not match between CPU and GPU implementations.\" << std::endl;\n",
        "    }\n",
        "\n",
        "    cudaFree(d_matrixA);\n",
        "    cudaFree(d_matrixB);\n",
        "    cudaFree(d_matrixC);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10p8CmRf30Qs",
        "outputId": "55440572-24d6-4707-93e9-d4665a074974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix A:\n",
            "1 2 3 \n",
            "4 5 6 \n",
            "7 8 9 \n",
            "\n",
            "Matrix B:\n",
            "9 8 7 \n",
            "6 5 4 \n",
            "3 2 1 \n",
            "\n",
            "Result from CPU (matrixC_cpu):\n",
            "30 24 18 \n",
            "84 69 54 \n",
            "138 114 90 \n",
            "\n",
            "Result from GPU (matrixC_gpu):\n",
            "30 24 18 \n",
            "84 69 54 \n",
            "138 114 90 \n",
            "\n",
            "Results match between CPU and GPU implementations.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-rVrW-gn37r2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}